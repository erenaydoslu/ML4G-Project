{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "#import torch\n",
    "from torch.nn import ModuleList\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from torch_geometric.loader import ClusterData, ClusterLoader, NeighborSampler, NeighborLoader\n",
    "\n",
    "# import the functions\n",
    "from numpy import dot\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import the datasets\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_data = np.load('data/preprocessed/dynamic_data.npy')\n",
    "static_data = np.load('data/preprocessed/static_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2628, 279)\n"
     ]
    }
   ],
   "source": [
    "print(dynamic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  GTCNN.zip\n",
      "   creating: GTCNN/.ipynb_checkpoints/\n",
      "  inflating: GTCNN/.ipynb_checkpoints/parametric_pooling_net-checkpoint.py  \n",
      "   creating: GTCNN/__pycache__/\n",
      "  inflating: GTCNN/__pycache__/parametric_pooling_net.cpython-310.pyc  \n",
      "  inflating: GTCNN/__pycache__/parametric_pooling_net_ordering.cpython-310.pyc  \n",
      "   creating: GTCNN/components/\n",
      "   creating: GTCNN/components/__pycache__/\n",
      "  inflating: GTCNN/components/__pycache__/evaluation.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/__pycache__/GGRNN.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/__pycache__/graph_utils.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/__pycache__/lsigf.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/__pycache__/parametric_graph_filter.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/__pycache__/plot_utils.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/__pycache__/pred_utils.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/__pycache__/space_time_pooling.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/__pycache__/train_utils.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/evaluation.py  \n",
      "  inflating: GTCNN/components/graph_utils.py  \n",
      "   creating: GTCNN/components/grnn/\n",
      " extracting: GTCNN/components/grnn/__init__.py  \n",
      "   creating: GTCNN/components/grnn/__pycache__/\n",
      "  inflating: GTCNN/components/grnn/__pycache__/__init__.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/grnn/__pycache__/__init__.cpython-38.pyc  \n",
      "  inflating: GTCNN/components/grnn/__pycache__/architecture.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/grnn/__pycache__/architecture.cpython-38.pyc  \n",
      "  inflating: GTCNN/components/grnn/__pycache__/utils.cpython-310.pyc  \n",
      "  inflating: GTCNN/components/grnn/__pycache__/utils.cpython-38.pyc  \n",
      "  inflating: GTCNN/components/grnn/architecture.py  \n",
      "  inflating: GTCNN/components/grnn/graphTools.py  \n",
      "  inflating: GTCNN/components/grnn/utils.py  \n",
      "  inflating: GTCNN/components/lsigf.py  \n",
      "  inflating: GTCNN/components/parametric_graph_filter.py  \n",
      "  inflating: GTCNN/components/plot_utils.py  \n",
      "  inflating: GTCNN/components/pred_utils.py  \n",
      "  inflating: GTCNN/components/space_time_pooling.py  \n",
      "  inflating: GTCNN/components/train_utils.py  \n",
      "  inflating: GTCNN/parametric_pooling_net.py  \n"
     ]
    }
   ],
   "source": [
    "!unzip GTCNN.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = [.3, .2, .5] # [.3, .2, .5]; train, validation, test portions -- summed up to 1\n",
    "pred_horizen = 1\n",
    "obs_window = 4\n",
    "n_listings = dynamic_data.shape[0]\n",
    "n_timestamps = dynamic_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has been created.\n",
      "-------------------------\n",
      "79 train data points\n",
      "52 validation data points\n",
      "136 test data points\n"
     ]
    }
   ],
   "source": [
    "from GTCNN.components.train_utils import create_forecasting_dataset\n",
    "\n",
    "dataset = create_forecasting_dataset(dynamic_data,\n",
    "                                     splits = split,\n",
    "                                     pred_horizen= pred_horizen,\n",
    "                                     obs_window= obs_window,\n",
    "                                     in_sample_mean= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset['trn']['data']\n",
    "x_test = dataset['tst']['data']\n",
    "x_val = dataset['val']['data']\n",
    "y_val = dataset['val']['labels']\n",
    "y_train = dataset['trn']['labels']\n",
    "y_test = dataset['trn']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, in_dim,out_dim,in_head = 8,out_head = 1):\n",
    "        super(GAT, self).__init__()\n",
    "        self.hid = hidden_size\n",
    "        self.in_head = in_head\n",
    "        self.out_head = out_head\n",
    "        \n",
    "        \n",
    "        self.conv1 = GATv2Conv(in_dim, self.hid, heads=self.in_head, dropout=0.6)\n",
    "        self.conv2 = GATv2Conv(self.hid*self.in_head, out_dim, concat=False,\n",
    "                             heads=self.out_head, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "                \n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "\n",
    "criterion = MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "\n",
    "model = GAT(hidden_size=8, in_dim = x_train.shape[2], out_dim = x_train.shape[1]).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x_train)\n",
    "    loss = criterion(out, y_train)\n",
    "    \n",
    "    if epoch%200 == 0:\n",
    "        print(loss)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, pred = model(x_test).max(dim=1)\n",
    "correct = float(pred.eq(y_test).sum().item())\n",
    "acc = correct / x_test.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
