{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e07a33-303f-4005-8390-b46ecf6d0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import psutil\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b916a696-ceaa-4715-9e3e-e93a71399965",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "def generate_parametric_product_graph(s00, s01, s10, s11, A_T, A_N, spatial_graph):\n",
    "    #print(\"Generating product graph...\")\n",
    "    I_T = np.identity(len(A_T))\n",
    "    I_N = np.identity(len(A_N))\n",
    "    S_diamond = (\n",
    "        s00 * np.kron(I_T, I_N) +\n",
    "        s01 * np.kron(I_T, A_N) +\n",
    "        s10 * np.kron(A_T, I_N) +\n",
    "        s11 * np.kron(A_T, A_N)\n",
    "    )\n",
    "    product_graph = nx.from_numpy_array(S_diamond)\n",
    "    \n",
    "    # Add features to the product graph\n",
    "    num_nodes = A_N.shape[0]\n",
    "    num_timesteps = A_T.shape[0]\n",
    "    \n",
    "    for t in range(num_timesteps):\n",
    "        for node in range(num_nodes):\n",
    "            original_node = node #node_list[node]  # Adjust if necessary\n",
    "            new_node = t * num_nodes + node\n",
    "            product_graph.nodes[new_node]['feature'] = spatial_graph.nodes[original_node]['feature']\n",
    "    \n",
    "    #print(\"Product graph generated\")\n",
    "    return product_graph\n",
    "\n",
    "\n",
    "def perform_spectral_clustering(n_clusters, adj):\n",
    "    #print(\"Clustering...\")\n",
    "    spectral = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', assign_labels='kmeans')\n",
    "    labels = spectral.fit_predict(adj)\n",
    "    \n",
    "    # Generate adjacency matrices for subgraphs based on clustering labels\n",
    "    subgraph_adj_matrices = []\n",
    "    original_node_ids = []\n",
    "    \n",
    "    for cluster in range(n_clusters):\n",
    "        nodes_in_cluster = [i for i in range(len(labels)) if labels[i] == cluster]\n",
    "        subgraph_adj_matrix = adj[np.ix_(nodes_in_cluster, nodes_in_cluster)]\n",
    "        subgraph_adj_matrices.append(subgraph_adj_matrix)\n",
    "        if cluster < len(listings):\n",
    "            node_ids = listings.iloc[nodes_in_cluster]['id'].tolist()\n",
    "            original_node_ids.append(node_ids)\n",
    "    \n",
    "    #print(\"Clustering completed\")\n",
    "    return subgraph_adj_matrices, original_node_ids\n",
    "\n",
    "\n",
    "\n",
    "def sample_nodes(adj_matrix, M, k):\n",
    "    \"\"\"\n",
    "    Perform spatial clustering by sampling M nodes and including their top-k neighbors based on edge weights.\n",
    "    \n",
    "    Parameters:\n",
    "    adj_matrix (torch.Tensor): The adjacency matrix of the entire graph (shape: [num_nodes, num_nodes]).\n",
    "    M (int): The number of nodes to sample.\n",
    "    k (int): The number of top neighbors to sample based on edge weights.\n",
    "    \n",
    "    Returns:\n",
    "    list: List of node indices of the sampled nodes and their neighbors.\n",
    "    torch.Tensor: The adjacency matrix of the subgraph.\n",
    "    \"\"\"\n",
    "    num_nodes = adj_matrix.shape[0]\n",
    "    \n",
    "    # Sample M unique nodes\n",
    "    sampled_nodes = np.random.choice(num_nodes, M, replace=False)\n",
    "    \n",
    "    # Create a mask for sampled nodes and their top-k neighbors\n",
    "    node_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    node_mask[sampled_nodes] = True\n",
    "    if isinstance(adj_matrix, np.ndarray):\n",
    "        adj_matrix = torch.tensor(adj_matrix, dtype=torch.float)\n",
    "    for node in sampled_nodes:\n",
    "        # Get the neighbors and their edge weights\n",
    "        neighbors = torch.nonzero(adj_matrix[node] > 0).view(-1)\n",
    "        neighbor_weights = adj_matrix[node, neighbors]\n",
    "        \n",
    "        # Sort neighbors by edge weight and take the top k\n",
    "        if neighbors.size(0) > k:\n",
    "            top_k_neighbors = neighbors[torch.topk(neighbor_weights, k).indices]\n",
    "        else:\n",
    "            top_k_neighbors = neighbors\n",
    "        \n",
    "        node_mask[top_k_neighbors] = True\n",
    "    \n",
    "    # Get the final list of nodes (sampled nodes + their top-k neighbors)\n",
    "    final_nodes = torch.nonzero(node_mask).view(-1)\n",
    "    \n",
    "    # Create the subgraph adjacency matrix\n",
    "    subgraph_adj_matrix = adj_matrix[final_nodes][:, final_nodes]\n",
    "    \n",
    "    return final_nodes.tolist(), subgraph_adj_matrix\n",
    "\n",
    "def adjacency_to_edge_list(adj):\n",
    "    edge_list = []\n",
    "    num_nodes = adj.shape[0]\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if adj[i][j] != 0:\n",
    "                edge_list.append((i,j))\n",
    "    edge_list = np.array(edge_list)\n",
    "    return edge_list\n",
    "    \n",
    "def create_sequences(listing_ids,obs_window,pred_horizon):\n",
    "    # nodes is the index of the nodes in the graph\n",
    "    calendar = pd.read_csv(folder+'preprocessed/calendar.csv')\n",
    "    calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "    filtered_calendar = calendar[calendar['listing_id'].isin(listing_ids)]\n",
    "    price_matrix = filtered_calendar.pivot(index='listing_id', columns='date', values='price')\n",
    "    X, y = [], []\n",
    "    for listing_id in price_matrix.index:\n",
    "        data = price_matrix.loc[listing_id].values\n",
    "        for i in range(len(data) - T - h + 1):\n",
    "            X.append(data[i:i+T])\n",
    "            y.append(data[i+T+h-1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def add_features_to_graph(node_list, graph, features):\n",
    "    for i, node in enumerate(node_list):\n",
    "        graph.nodes[i]['feature'] = {feature: features[feature][node] for feature in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c257ef80-d9d0-4f9d-89b0-a2ebfc655447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24207689581117992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5506</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>t</td>\n",
       "      <td>-0.032965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5506</td>\n",
       "      <td>2016-12-02</td>\n",
       "      <td>t</td>\n",
       "      <td>-0.032965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5506</td>\n",
       "      <td>2016-12-03</td>\n",
       "      <td>t</td>\n",
       "      <td>-0.032965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5506</td>\n",
       "      <td>2016-12-04</td>\n",
       "      <td>t</td>\n",
       "      <td>-0.032965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5506</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>t</td>\n",
       "      <td>-0.032965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  listing_id        date available     price\n",
       "0           0        5506  2016-12-01         t -0.032965\n",
       "1           1        5506  2016-12-02         t -0.032965\n",
       "2           2        5506  2016-12-03         t -0.032965\n",
       "3           3        5506  2016-12-04         t -0.032965\n",
       "4           4        5506  2016-12-05         t -0.032965"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#folder = \"/home/dlayh/Coding/Graph_Project/ML4G-Project-main/data/\"\n",
    "folder = \"\"\n",
    "file = \"adjacency/coords_features\"\n",
    "#file = \"sigma25\"\n",
    "#file = \"sigma2\"\n",
    "adj = np.load(folder+file+'.npy')\n",
    "calendar = pd.read_csv(folder+'preprocessed/calendar.csv')\n",
    "listings = pd.read_csv(folder+'preprocessed/listings.csv')\n",
    "#prices = calendar[['price']]\n",
    "prices = np.log10(calendar['price'].to_numpy())\n",
    "\n",
    "PRICE_MEAN = prices.mean()\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the \"price\" column\n",
    "scaled_prices = prices - PRICE_MEAN\n",
    "\n",
    "# Convert the result back to a DataFrame and update the original DataFrame\n",
    "calendar['price'] = scaled_prices\n",
    "# Initialize the StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the \"price\" column\n",
    "#scaled_prices = scaler.fit_transform(prices)\n",
    "\n",
    "# Convert the result back to a DataFrame and update the original DataFrame\n",
    "#calendar['price'] = scaled_prices\n",
    "\n",
    "pred_horizon = 1\n",
    "obs_window = 3\n",
    "\n",
    "# Assuming 4 timesteps and predicting a fifth timestep\n",
    "A_T = np.array([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 1, 0]\n",
    "])\n",
    "# Assuming 3 timesteps and predicting a fourth timestep\n",
    "A_T = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 0]\n",
    "])\n",
    "binary_adj = [1 for y in adj for x in y if x!=0]\n",
    "print(sum(binary_adj)/adj.shape[0]**2)\n",
    "\n",
    "#subgraphs_adj,original_node_indices = perform_spectral_clustering(10,adj)\n",
    "node_list, sampled_adj = sample_nodes(adj, 100, 4)\n",
    "spatial_graph = nx.from_numpy_array(sampled_adj.numpy())\n",
    "\n",
    "features = ['minimum_nights','square_feet','bathrooms', 'bedrooms', 'beds', 'bed_type']\n",
    "node_features = listings[features]\n",
    "\n",
    "add_features_to_graph(node_list, spatial_graph, node_features)\n",
    "\n",
    "product_graph = generate_parametric_product_graph(0, 1, 1, 1, A_T, sampled_adj, spatial_graph)\n",
    "\n",
    "def add_labels(G,node_list,time_steps,starting_date):\n",
    "    num_nodes = len(G.nodes) \n",
    "    #print(num_nodes,len(node_list))\n",
    "    for t in range(time_steps):\n",
    "        date_obj = datetime.strptime(starting_date, '%Y-%m-%d')\n",
    "        new_date_obj = date_obj + timedelta(days=t)\n",
    "        new_date_str = new_date_obj.strftime('%Y-%m-%d')\n",
    "        labels = calendar[calendar[\"date\"] == new_date_str]\n",
    "        for node in range(len(node_list)):\n",
    "            label = labels.iloc[node_list[node]].price\n",
    "            original_node = node #node_list[node] \n",
    "            new_node = (t * len(node_list)) + node \n",
    "            #print(new_node, len(node_list))\n",
    "            #if new_node >= num_nodes:\n",
    "            #    break\n",
    "            G.nodes[new_node]['label'] = label \n",
    "    return G\n",
    "\n",
    "labeled_product_graph = add_labels(product_graph,node_list,obs_window+pred_horizon,starting_date = '2016-12-01')\n",
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8ab630-ce51-48ae-bc13-9ffbd9d6c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tikhonov(lambda_reg, signals, laplacian, matrix):\n",
    "    matrix = np.diag(matrix)\n",
    "    A = np.matmul(matrix.T,matrix) + lambda_reg*laplacian\n",
    "    B = np.matmul(np.matmul(matrix.T,matrix),signals)\n",
    "    return np.matmul(np.linalg.inv(A),B)\n",
    "\n",
    "def modified_tikhonov(lambda_reg_space,lambda_reg_time, signals, time_laplacian,space_laplacian, matrix):\n",
    "    matrix = np.diag(matrix)\n",
    "    A = np.matmul(matrix.T,matrix) + lambda_reg_space*space_laplacian + lambda_reg_time*time_laplacian\n",
    "    B = np.matmul(np.matmul(matrix.T,matrix),signals)\n",
    "    return np.matmul(np.linalg.inv(A),B)\n",
    "\n",
    "\n",
    "def TV_reg(lambda_reg, signals, laplacian, matrix):\n",
    "    matrix = np.diag(matrix)\n",
    "    A = np.matmul(matrix.T,matrix) + lambda_reg*np.matmul((np.identity(len(laplacian))-laplacian),(np.identity(len(laplacian))-laplacian).T)\n",
    "    B = np.matmul(np.matmul(matrix.T,matrix),signals)\n",
    "    return np.matmul(np.linalg.inv(A),B)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def lasso_regression(lambda_reg, y, laplacian, mask):\n",
    "    L = laplacian\n",
    "    mask_diag = np.diag(mask)\n",
    "    \n",
    "    # Apply the mask to the Laplacian and y\n",
    "    masked_L = np.matmul(mask_diag, L)\n",
    "    masked_y = np.matmul(mask_diag, y)\n",
    "    \n",
    "    # Lasso regression model\n",
    "    lasso = Lasso(alpha=lambda_reg, fit_intercept=False, positive=True, max_iter=10000)\n",
    "    lasso.fit(masked_L, masked_y)\n",
    "    \n",
    "    return lasso.coef_\n",
    "    \n",
    "    return ridge.coef_\n",
    "def construct_laplacian(adj_matrix):\n",
    "    degree_matrix = np.diag(np.sum(adj_matrix, axis=1))\n",
    "    laplacian = degree_matrix - adj_matrix\n",
    "    return laplacian\n",
    "def construct_spatial_laplacian(adj_matrix):\n",
    "    mask_diag = np.identity(len(adj_matrix))\n",
    "    adj_matrix = mask_diag * adj_matrix\n",
    "    degree_matrix = np.diag(np.sum(adj_matrix, axis=1))\n",
    "    laplacian = degree_matrix - adj_matrix\n",
    "    return laplacian\n",
    "\n",
    "def construct_temporal_laplacian(T):\n",
    "    temporal_graph = nx.path_graph(T)\n",
    "    adj_matrix = nx.adjacency_matrix(temporal_graph).toarray()\n",
    "    degree_matrix = np.diag(np.sum(adj_matrix, axis=1))\n",
    "    laplacian = degree_matrix - adj_matrix\n",
    "    return laplacian\n",
    "def modify_laplacian_for_temporal_emphasis(laplacian, N, T):\n",
    "    I_spatial = np.kron(np.eye(T), np.ones((N, N)))  # Identity matrix for spatial connections\n",
    "    I_temporal = np.kron(np.ones((T, T)), np.eye(N))  # Identity matrix for temporal connections\n",
    "    \n",
    "    lap_space =  laplacian * I_spatial\n",
    "    lap_temp = laplacian * I_temporal\n",
    "    return lap_space,lap_temp\n",
    "\n",
    "def elastic_net_regression(alpha, l1_ratio, y, laplacian, mask):\n",
    "    mask_diag = np.diag(mask)\n",
    "    \n",
    "    # Apply the mask to the Laplacian and y\n",
    "    masked_L = mask_diag @ laplacian\n",
    "    masked_y = mask_diag @ y\n",
    "    \n",
    "    # Elastic Net regression model\n",
    "    elastic_net = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=False, max_iter=10000)\n",
    "    elastic_net.fit(masked_L, masked_y)\n",
    "    \n",
    "    return elastic_net.coef_\n",
    "def find_best_hyperparameters(y, laplacian, mask):\n",
    "    mask_diag = np.diag(mask)\n",
    "    masked_L = mask_diag @ laplacian\n",
    "    masked_y = mask_diag @ y\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'alpha': np.logspace(-4, 1, 2),\n",
    "        'l1_ratio': np.linspace(0.0001, 1, 2)\n",
    "    }\n",
    "    \n",
    "    # Create the ElasticNet model\n",
    "    elastic_net = ElasticNet(fit_intercept=False, max_iter=10000)\n",
    "    \n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Perform the grid search\n",
    "    grid_search.fit(masked_L, masked_y)\n",
    "    \n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0d2e16-6857-4774-8c1c-3529adf47dee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████| 279/279 [12:10<00:00,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09088180370123376\n",
      "615.7449270062571\n",
      "-0.20252415827279485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def regularize(labeled_product_graph,plot=False):\n",
    "    \n",
    "    signals = []\n",
    "    block_size = len(node_list)+1 # 4 timesteps, \n",
    "    N = block_size-1\n",
    "    T = 4   # Number of timesteps\n",
    "    for node in labeled_product_graph.nodes():\n",
    "        try:\n",
    "            signals.append(labeled_product_graph.nodes[node]['label'])\n",
    "        except KeyError:\n",
    "            print(f\"Node {node} is missing 'label' attribute.\")\n",
    "    \n",
    "    signals = np.array(signals)\n",
    "    adj_matrix = nx.adjacency_matrix(labeled_product_graph).toarray()\n",
    "    binary_adj_matrix = (adj_matrix > 0).astype(int)\n",
    "    #laplacian = construct_laplacian(adj_matrix)\n",
    "    \n",
    "    laplacian = construct_laplacian(binary_adj_matrix)\n",
    "    laplacian_spatial,laplacian_temporal = modify_laplacian_for_temporal_emphasis(laplacian, N, T)\n",
    "    \n",
    "    #laplacian_spatial = construct_spatial_laplacian(labeled_product_graph)\n",
    "    #laplacian_temporal = construct_temporal_laplacian(labeled_product_graph)\n",
    "    # Mask a certain percentage of node signals\n",
    "    \n",
    "    # Create a mask where the last block is set to 0 (missing)\n",
    "    mask = np.ones_like(signals)\n",
    "    mask[-block_size:] = 0\n",
    "    #print(mask)\n",
    "    masked_signals = signals * mask\n",
    "    alpha = [0]#np.linspace(1e-10,100,20)\n",
    "    l1_ratio = [1e-20]#np.linspace(1e-10,1,10)\n",
    "    lambda_reg_spatial = [0]#np.linspace(1e-100,100,20)\n",
    "    lambda_reg = [0]#np.linspace(1e-100,100,20)\n",
    "    #for j in alpha:#_temporal:\n",
    "        #for i in l1_ratio:\n",
    "    # Mix between L1 and L2 (0.5 means equal contribution)\n",
    "    \n",
    "    # Estimate the missing signals using Elastic Net regularization\n",
    "    #stimated_signals = elastic_net_regression(j, i, masked_signals, laplacian, mask)\n",
    "    estimated_signals = TV_reg(1e-20, masked_signals, laplacian, mask)\n",
    "    #estimated_signals = lasso_regression(i, masked_signals, laplacian, mask)\n",
    "    #estimated_signals = modified_tikhonov(i, j, \n",
    "    #                                      masked_signals,  laplacian_temporal,laplacian_spatial, mask)\n",
    "    # Reconstruct the original signal by replacing the masked indices with the estimated values\n",
    "    reconstructed_signals = np.copy(signals)\n",
    "    reconstructed_signals[-block_size:] = estimated_signals[-block_size:]\n",
    "    \n",
    "    # Calculate MSE between the original and estimated signals for the last block\n",
    "    original_signals_last_block = signals[-block_size:]\n",
    "    estimated_signals_last_block = estimated_signals[-block_size:]\n",
    "    size = len(original_signals_last_block)\n",
    "    largest_square_size = int(np.floor(np.sqrt(size))) ** 2\n",
    "    sqrt_size = int(np.sqrt(largest_square_size))\n",
    "    original_signals_last_block = original_signals_last_block[:largest_square_size]\n",
    "    estimated_signals_last_block = estimated_signals_last_block[:largest_square_size]\n",
    "    original_signals_last_block = np.reshape(original_signals_last_block,(sqrt_size,sqrt_size))\n",
    "    estimated_signals_last_block = np.reshape(estimated_signals_last_block,(sqrt_size,sqrt_size))\n",
    "    mse = mean_squared_error(original_signals_last_block, estimated_signals_last_block)\n",
    "    mae = mean_absolute_error(10**(original_signals_last_block+PRICE_MEAN), 10**(estimated_signals_last_block+PRICE_MEAN))\n",
    "    r2 = r2_score(original_signals_last_block, estimated_signals_last_block)\n",
    "\n",
    "    #print(\"Original Signals in Last Block: \", original_signals_last_block,\n",
    "    #      sum(original_signals_last_block)/len(original_signals_last_block))\n",
    "    #print(\"Masked Signals in Last Block: \", masked_signals[-block_size:])\n",
    "    #print(\"Estimated Signals in Last Block: \", estimated_signals_last_block,\n",
    "    #     sum(estimated_signals_last_block)/len(estimated_signals_last_block))\n",
    "    #print(\"Reconstructed Signals: \", reconstructed_signals)\n",
    "    if plot==True:\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            relative_error_matrix = np.abs((original_signals_last_block - estimated_signals_last_block) / original_signals_last_block) * 100\n",
    "            relative_error_matrix[original_signals_last_block == 0] = np.nan  # Assign NaN where true_matrix is 0\n",
    "        vmin, vmax = min(np.min(original_signals_last_block), np.min(estimated_signals_last_block)), max(np.max(original_signals_last_block), np.max(estimated_signals_last_block))\n",
    "        #, axes = plt.subplots(1, 3, figsize=(16, 8))\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(original_signals_last_block, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "        plt.title('True Price')\n",
    "        plt.colorbar()\n",
    "        plt.savefig(\"true_matrix.png\", format='png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        # Save the predicted matrix plot\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(estimated_signals_last_block, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "        plt.title('Predicted Price')\n",
    "        plt.colorbar()\n",
    "        plt.savefig(\"predicted_matrix.png\", format='png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        # Save the relative error matrix plot\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(relative_error_matrix, cmap='viridis', vmin=0, vmax=100)\n",
    "        plt.title('Relative Error (%)')\n",
    "        plt.colorbar()\n",
    "        plt.savefig(\"relative_error_matrix.png\", format='png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    #print(\"MSE between original and estimated signals in last block: \", mse)\n",
    "    #print(sum(original_signals_last_block.flatten())/len(original_signals_last_block.flatten()))\n",
    "    #print(sum(estimated_signals_last_block.flatten())/len(estimated_signals_last_block.flatten()))\n",
    "    return mse,mae,r2\n",
    "\n",
    "mse_s=[]\n",
    "mae_s=[]\n",
    "r2_s = []\n",
    "starting_dates = list(set(calendar.date))\n",
    "#print(starting_dates[:10])\n",
    "for i in range(1):\n",
    "    for date in tqdm(starting_dates,total=len(starting_dates)):\n",
    "        node_list, sampled_adj = sample_nodes(adj, 100, 4)\n",
    "        spatial_graph = nx.from_numpy_array(sampled_adj.numpy())\n",
    "        \n",
    "        features = ['minimum_nights','square_feet','bathrooms', 'bedrooms', 'beds', 'bed_type']\n",
    "        node_features = listings[features]\n",
    "        \n",
    "        add_features_to_graph(node_list, spatial_graph, node_features)\n",
    "        \n",
    "        product_graph = generate_parametric_product_graph(0, 1, 1, 1, A_T, sampled_adj, spatial_graph)\n",
    "        labeled_product_graph = add_labels(product_graph,node_list,obs_window+pred_horizon,starting_date = '2016-12-01')\n",
    "        mse,mae,r2 = regularize(labeled_product_graph)\n",
    "        mse_s.append(mse)\n",
    "        mae_s.append(mae)\n",
    "        r2_s.append(r2)\n",
    "print(sum(mse_s)/len(mse_s))\n",
    "print(sum(mae_s)/len(mae_s))\n",
    "print(sum(r2_s)/len(r2_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37cf3bb-150a-42f5-a433-3ac38f869fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mse(a,b):\n",
    "    mse =0\n",
    "    for i in range(len(a)):\n",
    "        mse += (a[i]-b[i])**2\n",
    "    return mse/len(a)\n",
    "print(test_mse(original_signals_last_block,estimated_signals_last_block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605f417-2fbb-40a5-8101-b6144fc8e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_date = '2016-12-01'\n",
    "date_obj = datetime.strptime(starting_date, '%Y-%m-%d')\n",
    "t = 1\n",
    "new_date_obj = date_obj + timedelta(days=t)\n",
    "new_date_str = new_date_obj.strftime('%Y-%m-%d')\n",
    "print(new_date_str)\n",
    "temp = calendar[calendar[\"date\"] == new_date_str]\n",
    "temp.head()\n",
    "temp.loc[280].price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8b2329-d217-431a-b5e4-b40a0fc58149",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('edge_list.txt', 'w') as f:\n",
    "    for edge in edge_list:\n",
    "        f.write(f\"{edge[0]} {edge[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78781d47-c168-4342-929f-aab7d057e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 10516 nodes and 7606391 edges\n",
      "Directed: False\n"
     ]
    }
   ],
   "source": [
    "loaded_edge_list = []\n",
    "with open('edge_list.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        node1, node2 = map(int, line.split())\n",
    "        loaded_edge_list.append((node1, node2))\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(loaded_edge_list)\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "is_directed = G.is_directed()\n",
    "\n",
    "print(f\"Graph with {num_nodes} nodes and {num_edges} edges\")\n",
    "print(f\"Directed: {is_directed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e62188-21ce-4c39-8347-4f97897e7cea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m G_loaded\u001b[38;5;241m.\u001b[39madd_edges_from(loaded_edge_list)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Verify the graph\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m(G_loaded))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx' has no attribute 'info'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9506d3-f837-4b45-921d-2d6c8f234f90",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspring_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_loaded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m nx\u001b[38;5;241m.\u001b[39mdraw(G_loaded, pos, with_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, node_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightblue\u001b[39m\u001b[38;5;124m'\u001b[39m, node_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, font_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded Graph from Edge List\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/py-env/lib/python3.12/site-packages/networkx/utils/decorators.py:789\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 4:4\u001b[0m, in \u001b[0;36margmap_spring_layout_1\u001b[0;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[0;32m~/py-env/lib/python3.12/site-packages/networkx/drawing/layout.py:483\u001b[0m, in \u001b[0;36mspring_layout\u001b[0;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[1;32m    481\u001b[0m         nnodes, _ \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    482\u001b[0m         k \u001b[38;5;241m=\u001b[39m dom_size \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(nnodes)\n\u001b[0;32m--> 483\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[43m_sparse_fruchterman_reingold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     A \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mto_numpy_array(G, weight\u001b[38;5;241m=\u001b[39mweight)\n",
      "File \u001b[0;32m~/py-env/lib/python3.12/site-packages/networkx/utils/decorators.py:789\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[0;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(\u001b[38;5;241m*\u001b[39margs, __wrapper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 12:4\u001b[0m, in \u001b[0;36margmap__sparse_fruchterman_reingold_9\u001b[0;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[0;32m~/py-env/lib/python3.12/site-packages/networkx/drawing/layout.py:622\u001b[0m, in \u001b[0;36m_sparse_fruchterman_reingold\u001b[0;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[1;32m    620\u001b[0m distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(distance \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, distance)\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# the adjacency matrix row\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m Ai \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetrowview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# TODO: revisit w/ sparse 1D container\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;66;03m# displacement \"force\"\u001b[39;00m\n\u001b[1;32m    624\u001b[0m displacement[:, i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    625\u001b[0m     delta \u001b[38;5;241m*\u001b[39m (k \u001b[38;5;241m*\u001b[39m k \u001b[38;5;241m/\u001b[39m distance\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m Ai \u001b[38;5;241m*\u001b[39m distance \u001b[38;5;241m/\u001b[39m k)\n\u001b[1;32m    626\u001b[0m )\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/py-env/lib/python3.12/site-packages/scipy/sparse/_lil.py:431\u001b[0m, in \u001b[0;36m_lil_base.toarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrows):\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pos, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row):\n\u001b[0;32m--> 431\u001b[0m         d[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[i][pos]\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "pos = nx.spring_layout(G_loaded)\n",
    "nx.draw(G_loaded, pos, with_labels=True, node_color='lightblue', node_size=500, font_size=10)\n",
    "plt.title(\"Loaded Graph from Edge List\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a5cc0-370a-49c9-9150-1df78808ecde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py-env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
